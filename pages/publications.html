<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <meta name="author" content="Preetham Ganesh" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Preetham Ganesh | Publications</title>
    <link rel="icon" type="image/x-icon" href="../images/icon.png" />
    <link rel="stylesheet" type="text/css" href="../css/main.css" />
    <link
      href="http://fonts.googleapis.com/css?family=Roboto"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN"
      crossorigin="anonymous"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css"
    />
  </head>
  <body>
    <section>
      <div class="content">
        <h2 class="section-heading text-white">Publications</h2>
        <div class="card card-shadow">
          <div class="row">
            <div class="col-12 col-lg-1">
              <p class="text-grey mb-3 font-size-14">2021</p>
            </div>
            <div class="col-12 col-lg-11">
              <div class="row">
                <h6 class="text-light-grey mb-3">
                  POS-Tagging based Neural Machine Translation System for
                  European Languages using Transformers
                </h6>
              </div>
              <div class="row">
                <p class="font-size-14 text-grey">
                  <span class="text-cyan"><b>Authors:</b></span> Preetham
                  Ganesh,
                  <a
                    class="text-cyan"
                    href="https://www.linkedin.com/in/brawal/"
                    target="_blank"
                    ><span class="hover-underline-animation">
                      Bharat S. Rawal</span
                    ></a
                  >,
                  <a
                    class="text-cyan"
                    href="https://www.linkedin.com/in/dralexanderpeter/"
                    target="_blank"
                    ><span class="hover-underline-animation">
                      Alexander Peter</span
                    ></a
                  >,
                  <a
                    class="text-cyan"
                    href="https://www.linkedin.com/in/asgiri"
                    target="_blank"
                    ><span class="hover-underline-animation">
                      Andi Giri</span
                    ></a
                  >
                </p>
              </div>
              <div class="row">
                <p class="text-grey font-size-14">
                  This study addresses language barriers by proposing a novel
                  Neural Machine Translation (NMT) approach using inter-language
                  word similarity and Part-of-Speech (POS) tagging for model
                  training and testing. Two classical architectures, Luong
                  Attention-based Sequence-to-Sequence and Transformer models,
                  were used, with tokenization by SentencePiece and Subword Text
                  Encoder, respectively. The models were evaluated on Spanish,
                  French, and German datasets with BLEU, Precision, and METEOR
                  scores, showing promising results.
                </p>
              </div>
              <div class="row">
                <ul class="card-links-ul">
                  <li>
                    <a
                      class="font-size-14 card-links-btn"
                      target="_blank"
                      href="https://wseas.com/journals/articles.php?id=318"
                      ><i class="fa-solid fa-earth-americas"></i> DOI</a
                    >
                  </li>
                  <li>
                    <a
                      class="font-size-14 card-links-btn"
                      target="_blank"
                      href="docs/pos_tagging_nmt_paper.pdf"
                      ><i class="fa-regular fa-file"></i> PDF</a
                    >
                  </li>
                  <li>
                    <a
                      class="font-size-14 card-links-btn"
                      target="_blank"
                      href="https://github.com/preetham-ganesh/neural-machine-translation"
                      ><i class="fa-brands fa-github"></i> GitHub</a
                    >
                  </li>
                  <li>
                    <a
                      class="font-size-14 card-links-btn"
                      target="_blank"
                      href="https://www.youtube.com/watch?v=yXvOBjQ-UWk"
                      ><i class="fa-brands fa-youtube"></i> Video Demo</a
                    >
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <div class="card card-shadow">
          <div class="row">
            <div class="col-12 col-lg-1">
              <p class="text-grey mb-3 font-size-14">2020</p>
            </div>
            <div class="col-12 col-lg-11">
              <div class="row">
                <h6 class="text-light-grey mb-3">
                  Personalized system for human gym activity recognition using
                  an RGB camera
                </h6>
              </div>
              <div class="row">
                <p class="font-size-14 text-grey">
                  <span class="text-cyan"><b>Authors:</b></span> Preetham
                  Ganesh,
                  <a
                    class="text-cyan"
                    href="https://www.linkedin.com/in/reza-etemadi"
                    target="_blank"
                    ><span class="hover-underline-animation">
                      Reza Etemadi Idgahi</span
                    ></a
                  >,
                  <a
                    class="text-cyan"
                    href="https://www.linkedin.com/in/chinmayavenkatesh"
                    target="_blank"
                    ><span class="hover-underline-animation">
                      Chinmaya Basavanahally Venkatesh</span
                    ></a
                  >,
                  <a
                    class="text-cyan"
                    href="https://www.linkedin.com/in/ashwinrameshbabu"
                    target="_blank"
                    ><span class="hover-underline-animation">
                      Ashwin Ramesh Babu</span
                    ></a
                  >,
                  <a
                    class="text-cyan"
                    href="https://www.linkedin.com/in/maria-kyrarini"
                    target="_blank"
                    ><span class="hover-underline-animation">
                      Maria Kyrarini</span
                    ></a
                  >
                </p>
              </div>
              <div class="row">
                <p class="font-size-14 text-grey">
                  This paper presents a Human Activity Recognition system using
                  an RGB camera to classify gym activities (e.g., push-up,
                  squat) through models like SVM, Decision Tree, KNN, and Random
                  Forest, with the latter achieving 98.98% accuracy. A
                  repetition counter was developed using local minima analysis
                  and dynamic time warping to assess workout accuracy per
                  skeletal point. An interactive Android app was also built to
                  provide users insights into their workouts.
                </p>
              </div>
              <div class="row">
                <ul class="card-links-ul">
                  <li>
                    <a
                      class="font-size-14 card-links-btn"
                      target="_blank"
                      href="https://dl.acm.org/doi/abs/10.1145/3389189.3392611"
                      ><i class="fa-solid fa-earth-americas"></i> DOI</a
                    >
                  </li>
                  <li>
                    <a
                      class="font-size-14 card-links-btn"
                      target="_blank"
                      href="docs/gym_activity_paper.pdf"
                      ><i class="fa-regular fa-file"></i> PDF</a
                    >
                  </li>
                  <li>
                    <a
                      class="font-size-14 card-links-btn"
                      target="_blank"
                      href="https://github.com/preetham-ganesh/Personalized-System-for-Human-Gym-Activity-Recognition-using-an-RGB-Camera"
                      ><i class="fa-brands fa-github"></i> GitHub</a
                    >
                  </li>
                  <li>
                    <a
                      class="font-size-14 card-links-btn"
                      target="_blank"
                      href="https://www.youtube.com/watch?v=nSFvcZse8gc"
                      ><i class="fa-brands fa-youtube"></i> Video Demo</a
                    >
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
  </body>
</html>
